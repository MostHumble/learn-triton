{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgOUFj2Tqvrue2vlEu0qQW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "from triton.runtime import driver\n",
        "import tabulate"
      ],
      "metadata": {
        "id": "0jyolDB_g-h7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Mv6nDjK7w_yH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _seeded_dropout(\n",
        "    x_ptr,\n",
        "    output_ptr,\n",
        "    n_elements,\n",
        "    p,\n",
        "    seed,\n",
        "    BLOCK_SIZE: tl.constexpr,\n",
        "):\n",
        "    # compute memory offsets of elements handled by this instance\n",
        "    pid = tl.program_id(axis=0)\n",
        "    block_start = pid * BLOCK_SIZE\n",
        "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
        "    # load data from x\n",
        "    mask = offsets < n_elements\n",
        "    x = tl.load(x_ptr + offsets, mask=mask)\n",
        "    # randomly prune it\n",
        "    random = tl.rand(seed, offsets)\n",
        "    x_keep = random > p\n",
        "    # write-back\n",
        "    output = tl.where(x_keep, x / (1 - p), 0.0)\n",
        "    tl.store(output_ptr + offsets, output, mask=mask)\n",
        "\n",
        "\n",
        "def seeded_dropout(x, p, seed):\n",
        "    output = torch.empty_like(x)\n",
        "    assert x.is_contiguous()\n",
        "    n_elements = x.numel()\n",
        "    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']), )\n",
        "    _seeded_dropout[grid](x, output, n_elements, p, seed, BLOCK_SIZE=1024)\n",
        "    return output\n",
        "\n",
        "\n",
        "x = torch.randn(size=(10, ), device=device)\n",
        "# Compare this to the baseline - dropout mask is never instantiated!\n",
        "output = seeded_dropout(x, p=0.5, seed=123)\n",
        "output2 = seeded_dropout(x, p=0.5, seed=123)\n",
        "output3 = seeded_dropout(x, p=0.5, seed=512)\n",
        "\n",
        "print(\n",
        "    tabulate.tabulate([\n",
        "        [\"input\"] + x.tolist(),\n",
        "        [\"output (seed = 123)\"] + output.tolist(),\n",
        "        [\"output (seed = 123)\"] + output2.tolist(),\n",
        "        [\"output (seed = 512)\"] + output3.tolist(),\n",
        "    ]))\n"
      ],
      "metadata": {
        "id": "DT_G02GVhzAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68c930df-832e-4a76-86ab-e40e3a5f6ed2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------  ---------  ---------  --------  ---------  --------  --------  ---------  ---------  ---------  -------\n",
            "input                -0.809575  -0.445639  0.856024  -0.184584  -1.19222  -1.284    -0.397066  0.0317655  -0.265393  0.81817\n",
            "output (seed = 123)   0         -0.891278  0          0          0        -2.56801   0         0          -0.530786  1.63634\n",
            "output (seed = 123)   0         -0.891278  0          0          0        -2.56801   0         0          -0.530786  1.63634\n",
            "output (seed = 512)   0          0         1.71205   -0.369169   0        -2.56801  -0.794132  0           0         0\n",
            "-------------------  ---------  ---------  --------  ---------  --------  --------  ---------  ---------  ---------  -------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extend the kernel to operate over a matrix and use a vector of seeds - one per row."
      ],
      "metadata": {
        "id": "CgTzlDvExRNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _seeded_dropout(\n",
        "    input_ptr,\n",
        "    output_ptr,\n",
        "    input_row_stride,\n",
        "    output_row_stride,\n",
        "    n_cols,\n",
        "    p,\n",
        "    seeds,\n",
        "    BLOCK_SIZE: tl.constexpr,\n",
        "):\n",
        "\n",
        "    # the rows of the dropout are independent, so we parallelize across those\n",
        "    row_idx = tl.program_id(0)\n",
        "    # The stride represents how much we need to increase the pointer to advance 1 row\n",
        "    # = num columns for *contiguous* 2d matrices\n",
        "    row_start_ptr = input_ptr + row_idx * input_row_stride\n",
        "\n",
        "    # The block size is the next power of two greater than n_cols, so we can fit each\n",
        "    # row in a single block\n",
        "    col_offsets = tl.arange(0, BLOCK_SIZE)\n",
        "    input_ptrs = row_start_ptr + col_offsets\n",
        "\n",
        "    # Load the row into SRAM, using a mask since BLOCK_SIZE may be > than n_cols\n",
        "    row = tl.load(input_ptrs, mask=col_offsets < n_cols)\n",
        "\n",
        "    # get the seed of the row\n",
        "    seed = tl.load(seeds + row_idx)\n",
        "\n",
        "    # filter and scale\n",
        "    random = tl.rand(seed, col_offsets)\n",
        "    row_keep = random > p\n",
        "    dropout_output = tl.where(row_keep, row / (1 - p), 0.0)\n",
        "\n",
        "    # Write back output to DRAM\n",
        "    output_row_start_ptr = output_ptr + row_idx * output_row_stride\n",
        "    output_ptrs = output_row_start_ptr + col_offsets\n",
        "    tl.store(output_ptrs, dropout_output, mask=col_offsets < n_cols)\n",
        "\n",
        "def seeded_dropout(x, p, seeds):\n",
        "\n",
        "    n_rows, n_cols = x.shape\n",
        "\n",
        "    BLOCK_SIZE = triton.next_power_of_2(n_cols)\n",
        "\n",
        "    output = torch.empty_like(x)\n",
        "\n",
        "    n_elements = x.numel()\n",
        "\n",
        "    _seeded_dropout[(n_rows, )](\n",
        "        x,\n",
        "        output,\n",
        "        x.stride(0),\n",
        "        output.stride(0),\n",
        "        n_cols,\n",
        "        p,\n",
        "        seeds,\n",
        "        BLOCK_SIZE=BLOCK_SIZE,\n",
        "    )\n",
        "    return output\n",
        "\n",
        "x = torch.randn(size=(2, 5), device=device)\n",
        "# Compare this to the baseline - dropout mask is never instantiated!\n",
        "seeds = torch.tensor([123, 132], device=device)\n",
        "seeds2 = torch.tensor([123, 321], device=device)\n",
        "\n",
        "output = seeded_dropout(x, p=0.5, seeds=seeds)\n",
        "output2 = seeded_dropout(x, p=0.5, seeds=seeds2)\n",
        "\n",
        "print(\n",
        "    tabulate.tabulate([\n",
        "        [\"input\"] + x.tolist(),\n",
        "        [\"output (seed = 123, 132)\"] + output.tolist(),\n",
        "        [\"output (seed = 123, 321)\"] + output2.tolist(),\n",
        "    ]))\n"
      ],
      "metadata": {
        "id": "9sTYcU2TtQvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2338e49a-7104-4dc4-de64-e824e5a16622"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------  --------------------------------------------------------------------------------------------------------  -------------------------------------------------------------------------------------------------------\n",
            "input                     [-0.4968452453613281, -1.6862846612930298, 0.6759570837020874, -0.10347044467926025, 2.0680792331695557]  [0.21053476631641388, -1.7139315605163574, 0.7079384326934814, -1.3756039142608643, 1.4101020097732544]\n",
            "output (seed = 123, 132)  [0.0, -3.3725693225860596, 0.0, 0.0, 0.0]                                                                 [0.0, 0.0, 1.415876865386963, 0.0, 0.0]\n",
            "output (seed = 123, 321)  [0.0, -3.3725693225860596, 0.0, 0.0, 0.0]                                                                 [0.0, -3.427863121032715, 0.0, 0.0, 2.820204019546509]\n",
            "------------------------  --------------------------------------------------------------------------------------------------------  -------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3NKDCqq2Qx1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}